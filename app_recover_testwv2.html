<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">

    <title>高分融合（复原）标准测试</title>

    <script src="http://cdn.bootcss.com/jquery/2.1.4/jquery.min.js"></script>
    <link rel="stylesheet" href="http://cdn.bootcss.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <script src="http://cdn.bootcss.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/ol3/3.5.0/ol.css" type="text/css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/ol3/3.5.0/ol.js"></script>

    <link href="css/offcanvas.css" rel="stylesheet">

    <style>

        #layertree li > span {
            cursor: pointer;
        }

        .map {
            height: 100%;
            width: 100%;
        }
		
        .scrolly {
            overflow-y: auto;
        }
        .ah {
            height: 100%;
        }

        .hh {
            height: 50%;
        }
		
		.nopadding {
			padding: 0;
		}
		
    </style>
</head>
<body>

<div class="row ah">
    <div class="col-md-2 ah scrolly">
	<button id="switchFlipBtn" class="btn btn-primary btn-lg btn-block">选择是否切换显示</button>
		<div class="projects-header page-header">	 
		<h2 class="text-center">高分卫星融合（复原）</h2>
		<h2 class="text-center">客观测试方案</h2>
		</div>

		<p>
		　　融合的结果好坏一直没有让大多数人信服的客观测试标准，我们这里提出一个客观性很强的测试方案。其主要原理是用高分辨率数据集缩小退化后的结果作为输入，而以原有的数据作为理想目标，各种融合算法用其输出和理想目标比较，越接近的显然就越好。<br/><br/>
		　　目前商业卫星WV3的空间分辨率为全色0.3米多光谱1.2米，将其缩小4倍后可以仿真全色1.2米多光谱4.8米的卫星，这和我国主力卫星GF1(2/8米）和GF2(0.8/3.2米）很接近，而且可以将原来1.2米的多光谱数据作为理想目标。同样，类似的WV2（0.4/1.2）也可以作为测试案例的基础数据源。<br/><br/>
		　　测试比较了三种目前广泛使用商业遥感软件的融合算法，包括ENVI5的Gram-Schmidt算法、NNDifuse算法（最新的ENVI5.3才有）、PCI2013的PanSharp算法，以及Pixel-Knife的pkRecover算法。<br/><br/>
		　　这个测试来自一个WV2的样例数据集OR2A_Beijing_China_40cm_054000253010<br/><br/>
		　　从右侧的图像上看（左上GS，右上NN，左下PS，右下PK，切换的比较图为原来的MS数据），GS和PS在植被、水体上变动很大，彩色屋顶也有变化；NN在整个图像的亮度上就已经有较大的差异；而PK除了一些细节边缘部分外基本上就看不出的差异。<br/><br/>
		</p>
		
		<p>
		　　计算各种算法的结果和理想结果相减的残差（越小越好，为0表示和理想结果一模一样）：<br/>
		<ul>
			<li>GS:    0.045</li>
			<li>NN:    0.046</li>
			<li>PS:    0.044</li>
			<li>PK:    <b>0.036</b></li>
		</ul>
		</p>

		<p>
		　　另外一个保真准则是融合结果缩小4倍之后的结果应该和输入的4.8米多光谱一致，计算各种算法的结果和理想结果相减的残差（越小越好，为0表示和理想结果一模一样）：<br/>
		<ul>
			<li>GS:    0.020</li>
			<li>NN:    0.031</li>
			<li>PS:    0.022</li>
			<li>PK:    <b>0.006</b></li>
		</ul>
		</p>

		</div>

	
    <div class="col-md-5 ah nopadding">
		<div id="map1" class="aw hh"></div>
		<div id="map3" class="aw hh"></div>
	</div>
    <div class="col-md-5 ah nopadding">
		<div id="map2" class="aw hh"></div>
		<div id="map4" class="aw hh"></div>
	</div>
</div>

<script>

	urlbase = 'img/recover/wv2/';
	nameArray = new Array("ms.jpeg", "gs.jpeg","nn.jpeg","ps.jpeg","pk.jpeg");
	infoArray = new Array("原来的1.2米MS", "ENVI Gram-Schmidt","ENVI NNDiffuse","PCI2013 PanSharp","Pixel-Knife pkRecover");

    var extent1 = [0, 0, 1, 1];
    var projection1 = new ol.proj.Projection({
        code: 'xkcd-image',
        units: 'pixels',
        extent: extent1
    });
    view = new ol.View({
        projection: projection1,
        center: [0.5,0.5],
        zoom: 3
    });

	layerArray = new Array(nameArray.length);
	
	source0 = new ol.source.ImageStatic({
		attributions: [
			new ol.Attribution({
				html: infoArray[0]
			})
		],
		url: urlbase + nameArray[0],
		projection: projection1,
		imageExtent: extent1
	});

	layerArray[0] = new ol.layer.Image({
		source: source0
	});
	
	layerArray[0].setVisible(false);

	for (i = 1; i < nameArray.length; i++)
	{
		source1 = new ol.source.ImageStatic({
			attributions: [
				new ol.Attribution({
					html: infoArray[i]
				})
			],
			url: urlbase + nameArray[i],
			projection: projection1,
			imageExtent: extent1
		});

		layerArray[i] = new ol.layer.Image({
			source: source1
		});
		
		var attribution1 = new ol.control.Attribution({
			collapsed: false
		});

		var map= new ol.Map({
			layers: [
				new ol.layer.Group({
					layers: [ layerArray[i], layerArray[0] ]

				})
			],
			controls:  ol.control.defaults({attribution: false}).extend([attribution1]),
			renderer: 'canvas',
			target: 'map'+i,
			view: view
		});
	}

//=================

	doFlip = true;
	interval = 1000;
    clockid = setInterval('flipImage()', interval);
	
    function flipImage() {
		if (doFlip)
		{
			for (i = 0; i < nameArray.length; i++)
				layerArray[i].setVisible( !layerArray[i].getVisible() );
		}
    }


	function stopFlip()
	{
		doFlip = false;
		layerArray[0].setVisible( false );
		for (i = 1; i < nameArray.length; i++)
			layerArray[i].setVisible( true );
	}
	
	function runFlip()
	{
		doFlip = true;
	}
	
	var switchBtn = document.getElementById('switchFlipBtn');
    switchBtn.addEventListener('click', function() {	
		if (doFlip)
			stopFlip();
		else
			runFlip();
	});
	
</script>
</body>
</html>